{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":11699725,"sourceType":"datasetVersion","datasetId":7343599},{"sourceId":185693,"sourceType":"modelInstanceVersion","modelInstanceId":158308,"modelId":164716}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.model_download(\"google/paligemma-2/transformers/paligemma2-3b-pt-224\")\n\nprint(\"Path to model files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:35:33.437027Z","iopub.execute_input":"2025-05-11T11:35:33.437354Z","iopub.status.idle":"2025-05-11T11:35:34.059288Z","shell.execute_reply.started":"2025-05-11T11:35:33.437333Z","shell.execute_reply":"2025-05-11T11:35:34.058675Z"}},"outputs":[{"name":"stdout","text":"Path to model files: /kaggle/input/paligemma-2/transformers/paligemma2-3b-pt-224/1\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#!pip install torch>=2.0.0 torchvision --index-url https://download.pytorch.org/whl/cu118","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-09T13:25:36.444756Z","iopub.execute_input":"2025-05-09T13:25:36.444995Z","iopub.status.idle":"2025-05-09T13:28:23.462364Z","shell.execute_reply.started":"2025-05-09T13:25:36.444975Z","shell.execute_reply":"2025-05-09T13:28:23.460773Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Verify GPU\nimport torch\nprint(torch.__version__)\nprint(torch.cuda.is_available())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:29:12.268283Z","iopub.execute_input":"2025-05-11T11:29:12.268730Z","iopub.status.idle":"2025-05-11T11:29:16.708588Z","shell.execute_reply.started":"2025-05-11T11:29:12.268706Z","shell.execute_reply":"2025-05-11T11:29:16.707959Z"}},"outputs":[{"name":"stdout","text":"2.5.1+cu124\nTrue\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n\ndata = pd.read_csv(\"/kaggle/input/riscmm/RISCM/captions.csv\")\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T14:01:20.113798Z","iopub.execute_input":"2025-05-11T14:01:20.114144Z","iopub.status.idle":"2025-05-11T14:01:24.127172Z","shell.execute_reply.started":"2025-05-11T14:01:20.114119Z","shell.execute_reply":"2025-05-11T14:01:24.122701Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"  source split           image  \\\n0   NWPU  test  NWPU_31430.jpg   \n1   NWPU  test  NWPU_31431.jpg   \n2   NWPU  test  NWPU_31432.jpg   \n3   NWPU  test  NWPU_31433.jpg   \n4   NWPU  test  NWPU_31434.jpg   \n\n                                           caption_1  \\\n0   A gray plane on the runway and the lawn beside .   \n1  Three small planes parked in a line on the air...   \n2  A plane parked in a line on the airport with s...   \n3  A small plane and a big plane parked next to b...   \n4       Two planes parked next to boarding bridges .   \n\n                                           caption_2  \\\n0        A grey plane is on the runway by the lawn .   \n1  There are four aircraft on the open ground, Th...   \n2  A white plane was parked on the instruction li...   \n3  A white plane and a gray plane parked at the b...   \n4  Two aircraft were parked at the departure gates .   \n\n                                           caption_3  \\\n0  There is an airplane on the runway with a larg...   \n1  There are many planes of different sizes in a ...   \n2  An airplane parked in an open area with many c...   \n3  Two planes of different sizes are neatly parke...   \n4  Two planes of different sizes are neatly parke...   \n\n                                           caption_4  \\\n0  A plane is parked on the runway next to the gr...   \n1             Four planes are parked on the runway .   \n2              A plane is parked on the open space .   \n3  A large plane and a small plane are parked nea...   \n4       Two planes are parked next to the terminal .   \n\n                                           caption_5  \n0  There is a plane on the runway beside the grass .  \n1  Four planes of different sizes were on the mar...  \n2            There is 1 plane on the ground marked .  \n3              Two planes are on the marked ground .  \n4              Two planes are on the marked ground .  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>split</th>\n      <th>image</th>\n      <th>caption_1</th>\n      <th>caption_2</th>\n      <th>caption_3</th>\n      <th>caption_4</th>\n      <th>caption_5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NWPU</td>\n      <td>test</td>\n      <td>NWPU_31430.jpg</td>\n      <td>A gray plane on the runway and the lawn beside .</td>\n      <td>A grey plane is on the runway by the lawn .</td>\n      <td>There is an airplane on the runway with a larg...</td>\n      <td>A plane is parked on the runway next to the gr...</td>\n      <td>There is a plane on the runway beside the grass .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NWPU</td>\n      <td>test</td>\n      <td>NWPU_31431.jpg</td>\n      <td>Three small planes parked in a line on the air...</td>\n      <td>There are four aircraft on the open ground, Th...</td>\n      <td>There are many planes of different sizes in a ...</td>\n      <td>Four planes are parked on the runway .</td>\n      <td>Four planes of different sizes were on the mar...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NWPU</td>\n      <td>test</td>\n      <td>NWPU_31432.jpg</td>\n      <td>A plane parked in a line on the airport with s...</td>\n      <td>A white plane was parked on the instruction li...</td>\n      <td>An airplane parked in an open area with many c...</td>\n      <td>A plane is parked on the open space .</td>\n      <td>There is 1 plane on the ground marked .</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NWPU</td>\n      <td>test</td>\n      <td>NWPU_31433.jpg</td>\n      <td>A small plane and a big plane parked next to b...</td>\n      <td>A white plane and a gray plane parked at the b...</td>\n      <td>Two planes of different sizes are neatly parke...</td>\n      <td>A large plane and a small plane are parked nea...</td>\n      <td>Two planes are on the marked ground .</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NWPU</td>\n      <td>test</td>\n      <td>NWPU_31434.jpg</td>\n      <td>Two planes parked next to boarding bridges .</td>\n      <td>Two aircraft were parked at the departure gates .</td>\n      <td>Two planes of different sizes are neatly parke...</td>\n      <td>Two planes are parked next to the terminal .</td>\n      <td>Two planes are on the marked ground .</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"wandb.login(key=\"d070aabfe54f4733fb727662604b037dee34842c\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T11:31:00.901475Z","iopub.execute_input":"2025-05-11T11:31:00.901784Z","iopub.status.idle":"2025-05-11T11:31:01.189302Z","shell.execute_reply.started":"2025-05-11T11:31:00.901762Z","shell.execute_reply":"2025-05-11T11:31:01.188539Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madigew\u001b[0m (\u001b[33madigew-middle-east-technical-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom transformers import PaliGemmaForConditionalGeneration, PaliGemmaProcessor\nfrom peft import LoraConfig, get_peft_model\nfrom PIL import Image\nimport wandb\nimport os\nfrom torch.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\n\nclass RISCDataset(Dataset):\n    def __init__(self, image_dir, df, processor):\n        self.image_dir = image_dir\n        self.df = df\n        self.processor = processor\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = os.path.join(self.image_dir, row.image)\n        if not os.path.exists(image_path):\n            raise FileNotFoundError(f\"Image not found: {image_path}\")\n        image = Image.open(image_path).convert('RGB')\n        caption = row.caption_1\n        if pd.isna(caption):\n            raise ValueError(f\"Missing caption for image {row.image}\")\n        text_input = f\"<image> caption {caption}\"\n        inputs = self.processor(\n            text=text_input,\n            images=image,\n            return_tensors=\"pt\",\n            padding=\"longest\"\n        )\n        return inputs\n\ndef load_dataset(image_dir, caption_file):\n    df = pd.read_csv(caption_file)\n    train_df = df[df['split'] == 'train']\n    val_df = df[df['split'] == 'test']\n    return train_df, val_df\n\ndef train_lora(model_name, image_dir, caption_file, output_dir,\n               lora_rank=4, epochs=5, learning_rate=1e-5,\n               max_train_samples=None, max_val_samples=None,\n               batch_size=1, accum_steps=4):\n    \n    wandb.init(project=\"DI725_Phase2\", config={\n        \"lora_rank\": lora_rank,\n        \"epochs\": epochs,\n        \"lr\": learning_rate,\n        \"max_train_samples\": max_train_samples,\n        \"max_val_samples\": max_val_samples\n    })\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    if device.type != \"cuda\":\n        raise RuntimeError(\"GPU not available. Ensure you're using a GPU runtime in Colab.\")\n    \n    model = PaliGemmaForConditionalGeneration.from_pretrained(\n        model_name, torch_dtype=torch.float16).to(device)\n    processor = PaliGemmaProcessor.from_pretrained(model_name, use_fast=True)\n\n    lora_config = LoraConfig(\n        r=lora_rank,\n        lora_alpha=32,\n        target_modules=[\"q_proj\", \"v_proj\"],\n        lora_dropout=0.1\n    )\n    model = get_peft_model(model, lora_config)\n\n    train_df, val_df = load_dataset(image_dir, caption_file)\n    if max_train_samples:\n        train_df = train_df.iloc[:max_train_samples]\n    if max_val_samples:\n        val_df = val_df.iloc[:max_val_samples]\n    print(f\"Training on {len(train_df)} samples, validating on {len(val_df)} samples\")\n\n    train_dataset = RISCDataset(image_dir, train_df, processor)\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_dataset = RISCDataset(image_dir, val_df, processor)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n\n    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n    scaler = GradScaler()\n    model.train()\n\n    for epoch in range(epochs):\n        total_loss = 0\n        steps = 0\n        optimizer.zero_grad()\n        \n        for batch_idx, batch in enumerate(train_loader):\n            try:\n                batch = {k: v.squeeze(0).to(device) for k, v in batch.items()}\n\n                with autocast('cuda'):\n                    outputs = model(\n                        input_ids=batch['input_ids'],\n                        attention_mask=batch['attention_mask'],\n                        pixel_values=batch['pixel_values'],\n                        labels=batch['input_ids']\n                    )\n                    loss = outputs.loss / accum_steps\n                \n                scaler.scale(loss).backward()\n                \n                if (batch_idx + 1) % accum_steps == 0 or (batch_idx + 1) == len(train_loader):\n                    scaler.step(optimizer)\n                    scaler.update()\n                    optimizer.zero_grad()\n                \n                total_loss += loss.item() * accum_steps\n                steps += 1\n                if steps % 10 == 0:\n                    print(f\"Epoch {epoch+1}, Step {steps}, Loss: {loss.item() * accum_steps:.4f}\")\n                torch.cuda.empty_cache()\n            except Exception as e:\n                print(f\"Error in batch {batch_idx+1}: {e}\")\n                torch.cuda.empty_cache()\n                continue\n\n        avg_train_loss = total_loss / steps if steps > 0 else 0\n        wandb.log({\"epoch\": epoch+1, \"train_loss\": avg_train_loss})\n\n        model.eval()\n        val_loss = 0\n        val_steps = 0\n        for batch_idx, batch in enumerate(val_loader):\n            try:\n                batch = {k: v.squeeze(0).to(device) for k, v in batch.items()}\n                with torch.no_grad(), autocast('cuda'):\n                    outputs = model(\n                        input_ids=batch['input_ids'],\n                        attention_mask=batch['attention_mask'],\n                        pixel_values=batch['pixel_values'],\n                        labels=batch['input_ids']\n                    )\n                    val_loss += outputs.loss.item()\n                val_steps += 1\n                torch.cuda.empty_cache()\n            except Exception as e:\n                print(f\"Validation error {batch_idx+1}: {e}\")\n                torch.cuda.empty_cache()\n                continue\n\n        avg_val_loss = val_loss / val_steps if val_steps > 0 else 0\n        wandb.log({\"epoch\": epoch+1, \"val_loss\": avg_val_loss})\n        print(f\"Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}\")\n        model.train()\n\n    model.save_pretrained(output_dir)\n    processor.save_pretrained(output_dir)\n    wandb.finish()\n\nif __name__ == \"__main__\":\n    model_name = \"/kaggle/input/paligemma-2/transformers/paligemma2-3b-pt-224/1\"\n    image_dir = \"/kaggle/input/riscmm/RISCM/resized\"\n    caption_file = \"/kaggle/input/riscmm/RISCM/captions.csv\"\n    output_dir = \"/kaggle/working/paligemma_lora\"\n\n    train_lora(\n        model_name=model_name,\n        image_dir=image_dir,\n        caption_file=caption_file,\n        output_dir=output_dir,\n        max_train_samples=None,\n        max_val_samples=None\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-11T14:07:24.038916Z","iopub.execute_input":"2025-05-11T14:07:24.039223Z","iopub.status.idle":"2025-05-11T14:08:24.874357Z","shell.execute_reply.started":"2025-05-11T14:07:24.039197Z","shell.execute_reply":"2025-05-11T14:08:24.868117Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:251: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n  warnings.warn(\nWARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1746972490.527849      10 common_lib.cc:612] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:230\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpeft\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoraConfig, get_peft_model\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwandb\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'peft'"],"ename":"ModuleNotFoundError","evalue":"No module named 'peft'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}